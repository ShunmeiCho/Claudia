#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Production Commander - ç”Ÿäº§ç¯å¢ƒäº¤äº’å¼å‘½ä»¤å™¨
ä½¿ç”¨ä¿®å¤åçš„LLMå¤§è„‘æ¶æ„è¿›è¡Œå®æœºæµ‹è¯•
"""

import asyncio
import time
import sys
import os
from datetime import datetime
from typing import Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/m1ng/claudia')
sys.path.append('/home/m1ng/claudia/src')

from src.claudia.brain.production_brain import ProductionBrain, BrainOutput


class ProductionCommander:
    """ç”Ÿäº§ç¯å¢ƒå‘½ä»¤å™¨"""
    
    def __init__(self, use_real_hardware: bool = False):
        """åˆå§‹åŒ–å‘½ä»¤å™¨
        
        Args:
            use_real_hardware: æ˜¯å¦ä½¿ç”¨çœŸå®ç¡¬ä»¶ï¼ˆé»˜è®¤Falseä¸ºæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
        """
        self.brain = ProductionBrain(use_real_hardware=use_real_hardware)
        self.running = True
        self.command_history = []
        self.session_start = datetime.now()
        
    def print_header(self):
        """æ‰“å°ç•Œé¢å¤´éƒ¨"""
        print("\n" + "="*60)
        print("ğŸ¤– Claudia Production Commander - LLMå¤§è„‘å®æœºæµ‹è¯•")
        print("="*60)
        print(f"âš™ï¸  æ¨¡å¼: {'çœŸå®ç¡¬ä»¶' if self.brain.use_real_hardware else 'æ¨¡æ‹Ÿæ‰§è¡Œ'}")
        print(f"ğŸ§  æ¨¡å‹: {self.brain.model_7b}")
        print(f"â° ä¼šè¯å¼€å§‹: {self.session_start.strftime('%Y-%m-%d %H:%M:%S')}")
        print("-"*60)
        print("ğŸ’¡ æç¤º: è¾“å…¥æ—¥è¯­/ä¸­æ–‡/è‹±æ–‡å‘½ä»¤ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©")
        print("ğŸ’¡ ç¤ºä¾‹: ãŠæ‰‹, åä¸‹, dance, åº§ã£ã¦ã‹ã‚‰æŒ¨æ‹¶")
        print("-"*60 + "\n")
    
    def print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*40)
        print("ğŸ“– å¸®åŠ©ä¿¡æ¯")
        print("="*40)
        print("\nåŸºæœ¬å‘½ä»¤:")
        print("  ãŠæ‰‹, ãŠã™ã‚ã‚Š, ã‚¿ãƒƒãƒ†, ãƒãƒ¼ãƒˆ, ãƒ€ãƒ³ã‚¹")
        print("  åä¸‹, ç«™ç«‹, æ¯”å¿ƒ, æ¡æ‰‹, è·³èˆ")
        print("  sit, stand, heart, dance, hello")
        print("\nå¤æ‚å‘½ä»¤:")
        print("  åº§ã£ã¦ã‹ã‚‰æŒ¨æ‹¶ - åä¸‹ç„¶åæ‰“æ‹›å‘¼")
        print("  é‹å‹•ã—ã¦ - åšè¿åŠ¨")
        print("  è¡¨æ¼”ä¸€å¥— - è¡¨æ¼”ä¸€å¥—åŠ¨ä½œ")
        print("\nç³»ç»Ÿå‘½ä»¤:")
        print("  /help    - æ˜¾ç¤ºå¸®åŠ©")
        print("  /stats   - æ˜¾ç¤ºç»Ÿè®¡")
        print("  /history - æ˜¾ç¤ºå†å²")
        print("  /clear   - æ¸…å±")
        print("  /exit    - é€€å‡º")
        print("="*40 + "\n")
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.brain.get_statistics()
        print("\n" + "="*40)
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        print("="*40)
        print(f"ğŸ§  æ¨¡å‹: {stats['model']}")
        print(f"âš¡ ç¼“å­˜å¤§å°: {stats['cache_size']} æ¡")
        print(f"ğŸ¤– ç¡¬ä»¶æ¨¡å¼: {'çœŸå®' if stats['hardware_mode'] else 'æ¨¡æ‹Ÿ'}")
        print(f"ğŸ”Œ SportClient: {'å·²è¿æ¥' if stats['sport_client'] else 'æœªè¿æ¥'}")
        print(f"ğŸ“ å†å²å‘½ä»¤: {len(self.command_history)} æ¡")
        runtime = datetime.now() - self.session_start
        print(f"â±ï¸ è¿è¡Œæ—¶é—´: {runtime.total_seconds():.0f} ç§’")
        print("="*40 + "\n")
    
    def print_history(self):
        """æ‰“å°å†å²è®°å½•"""
        print("\n" + "="*40)
        print("ğŸ“œ å‘½ä»¤å†å²")
        print("="*40)
        if not self.command_history:
            print("(æš‚æ— å†å²è®°å½•)")
        else:
            for i, (timestamp, cmd, response) in enumerate(self.command_history[-10:], 1):
                print(f"{i}. [{timestamp}] {cmd}")
                print(f"   â†’ {response}")
        print("="*40 + "\n")
    
    async def _warmup_model(self):
        """é¢„çƒ­ LLM æ¨¡å‹ â€” ç›´æ¥è°ƒç”¨ Ollama API å°†æ¨¡å‹åŠ è½½åˆ° GPU æ˜¾å­˜

        ä¸èµ° process_command ç®¡çº¿ï¼ˆä¼šå‘½ä¸­ hot_cache ç»•è¿‡ LLMï¼‰ã€‚
        å‘é€ä¸€ä¸ªæçŸ­çš„æ¨ç†è¯·æ±‚ï¼Œè§¦å‘ Ollama å°†æ¨¡å‹æƒé‡åŠ è½½åˆ°æ˜¾å­˜ã€‚
        """
        print("ğŸ”„ é¢„çƒ­æ¨¡å‹ä¸­...")
        try:
            import ollama as _ollama
            model_name = self.brain.model_7b

            def _sync_warmup():
                return _ollama.chat(
                    model=model_name,
                    messages=[{'role': 'user', 'content': 'hi'}],
                    format='json',
                    options={
                        'num_predict': 1,   # åªç”Ÿæˆ1ä¸ªtokenï¼Œæœ€å°å¼€é”€
                        'num_ctx': 256,
                    },
                    keep_alive='30m',
                )

            loop = asyncio.get_event_loop()
            start = time.time()
            await asyncio.wait_for(
                loop.run_in_executor(None, _sync_warmup),
                timeout=60  # å†·åŠ è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
            )
            elapsed = (time.time() - start) * 1000
            print("âœ… æ¨¡å‹å°±ç»ª ({}: {:.0f}ms)".format(model_name, elapsed))
        except ImportError:
            print("âš ï¸ ollama åº“ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„çƒ­")
        except asyncio.TimeoutError:
            print("âš ï¸ æ¨¡å‹é¢„çƒ­è¶…æ—¶ (60s)ï¼Œç»§ç»­å¯åŠ¨")
        except Exception as e:
            print("âš ï¸ æ¨¡å‹é¢„çƒ­å¤±è´¥: {}ï¼Œç»§ç»­å¯åŠ¨".format(e))

    async def process_command(self, command: str):
        """å¤„ç†å•ä¸ªå‘½ä»¤"""
        if command.startswith("/"):
            # ç³»ç»Ÿå‘½ä»¤
            if command == "/help":
                self.print_help()
            elif command == "/stats":
                self.print_stats()
            elif command == "/history":
                self.print_history()
            elif command == "/clear":
                os.system('clear' if os.name == 'posix' else 'cls')
                self.print_header()
            elif command == "/exit":
                self.running = False
                print("\nğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨Claudia Production Commander\n")
            else:
                print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        else:
            # ç”¨æˆ·æŒ‡ä»¤ â€” ä½¿ç”¨åŸå­å…¥å£ process_and_executeï¼ˆPR2 è¿ç§»ï¼‰
            print(f"\nğŸ¯ å¤„ç†æŒ‡ä»¤: '{command}'")
            print("-"*40)

            start_time = time.time()
            brain_output = await self.brain.process_and_execute(command)
            process_time = (time.time() - start_time) * 1000

            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ’¬ å›å¤: {brain_output.response}")

            if brain_output.api_code:
                print(f"ğŸ”§ API: {brain_output.api_code}")

            if brain_output.sequence:
                print(f"ğŸ“‹ åºåˆ—: {brain_output.sequence}")

            print(f"â±ï¸ å¤„ç†æ—¶é—´: {process_time:.0f}ms")

            # æ‰§è¡ŒçŠ¶æ€ï¼ˆprocess_and_execute å†…å·²å®Œæˆæ‰§è¡Œï¼‰
            if brain_output.api_code or brain_output.sequence:
                print("-"*40)
                if brain_output.execution_status == "success":
                    print("âœ… æ‰§è¡ŒæˆåŠŸ")
                elif brain_output.execution_status == "unknown":
                    print("âš ï¸ åŠ¨ä½œè¶…æ—¶ï¼ˆæœºå™¨äººå¯è¾¾ï¼Œå¯èƒ½ä»åœ¨æ‰§è¡Œï¼‰")
                elif brain_output.execution_status == "failed":
                    print("âŒ æ‰§è¡Œå¤±è´¥")

            # è®°å½•å†å²
            timestamp = datetime.now().strftime("%H:%M:%S")
            self.command_history.append((
                timestamp,
                command,
                brain_output.response
            ))

            print("-"*40 + "\n")
    
    async def run(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        self.print_header()
        
        # é¢„çƒ­æ¨¡å‹: ç›´æ¥è°ƒç”¨ Ollama API å°†æ¨¡å‹åŠ è½½åˆ° GPU æ˜¾å­˜
        # æ³¨æ„: ä¸èƒ½ç”¨ process_command("hello") â€” "hello" å‘½ä¸­ hot_cacheï¼Œ
        # ä¼šè·³è¿‡ LLM æ¨ç†ï¼Œæ¨¡å‹ä¸ä¼šè¢«åŠ è½½åˆ°æ˜¾å­˜ä¸­
        await self._warmup_model()
        print("")
        
        # ä¸»å¾ªç¯
        while self.running:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                command = input("ãã‚‰> ").strip()
                
                if command:
                    await self.process_command(command)
                    
            except KeyboardInterrupt:
                print("\n\nâš ï¸ æ£€æµ‹åˆ°Ctrl+Cï¼Œæ­£åœ¨é€€å‡º...")
                self.running = False
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}\n")
        
        # æ¸…ç†
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        print("âœ… ä¼šè¯ç»“æŸ\n")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Claudia Production Commander")
    parser.add_argument(
        "--hardware",
        action="store_true",
        help="ä½¿ç”¨çœŸå®ç¡¬ä»¶æ¨¡å¼ï¼ˆé»˜è®¤ä¸ºæ¨¡æ‹Ÿæ¨¡å¼ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¹¶è¿è¡Œå‘½ä»¤å™¨
    commander = ProductionCommander(use_real_hardware=args.hardware)
    await commander.run()


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())
