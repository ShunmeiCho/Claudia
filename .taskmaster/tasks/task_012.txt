# Task ID: 12
# Title: Stage 1 End-to-End Voice Interaction & 'くらこい' Response
# Status: pending
# Dependencies: 6, 7, 8, 9, 10, 11
# Priority: high
# Description: Integrate all Stage 1 components: wake word, ASR, LLM, preset action execution, TTS, and LED feedback into a cohesive voice interaction flow. Implement the special "くらこい" / "くらおいで" direct call response and continuous dialogue mode.
# Details:
Orchestrate the full sequence: 1. Porcupine detects "ねえ、くら". 2. LED: Green double flash. 3. ASR processes subsequent user speech. 4. LED: Blue solid. 5. LLM interprets command. 6. Action mapped and executed via `unitree_sdk2py`. 7. LED: Orange solid during action. 8. TTS provides verbal feedback (if enabled). 9. LED: White 3 flashes on completion. For "くらこい"/"くらおいで": bypass wake word, perform sound localization (if possible, or default approach), approach user, execute friendly gesture. Implement continuous dialogue: after an action, wait ~10s for follow-up commands without re-wake. Timeout returns to listening.

# Test Strategy:
End-to-end test of the full interaction loop with various commands. Verify correct LED state transitions. Test "くらこい" response. Test continuous dialogue mode and timeout. Measure overall response latency (target <3s for simple commands, <4s for complex).
