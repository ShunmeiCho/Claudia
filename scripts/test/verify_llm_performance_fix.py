#!/usr/bin/env python3
"""
Claudia Robot - LLMæ€§èƒ½ä¼˜åŒ–éªŒè¯è„šæœ¬
éªŒè¯æ—¥å¿—é‡å¤é—®é¢˜ä¿®å¤å’Œ3Bæ¨¡å‹æ€§èƒ½ä¼˜åŒ–æ•ˆæœ
"""

import sys
import time
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from scripts.llm.claudia_llm_interface import ClaudiaLLMInterface

def test_performance_optimization():
    """æµ‹è¯•æ€§èƒ½ä¼˜åŒ–æ•ˆæœ"""
    print("ğŸ”§ Claudia LLMæ€§èƒ½ä¼˜åŒ–éªŒè¯")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–ä¼˜åŒ–åçš„æ¥å£
    llm = ClaudiaLLMInterface()
    
    # 2. æ˜¾ç¤ºä¼˜åŒ–é…ç½®
    print(f"\nğŸ“Š ä¼˜åŒ–é…ç½®:")
    print(f"  æ¨¡å‹: {llm.model_name}")
    print(f"  è¶…æ—¶: {llm.request_timeout}ç§’")
    print(f"  é‡è¯•æ¬¡æ•°: {llm.max_retries}")
    print(f"  æ¸©åº¦: {llm.model_params['temperature']}")
    print(f"  è¾“å‡ºé™åˆ¶: {llm.model_params['num_predict']}å­—ç¬¦")
    
    # 3. æ€§èƒ½æµ‹è¯•æ¡ˆä¾‹
    test_cases = [
        "åº§ã‚‹",
        "ã“ã‚“ã«ã¡ã¯",
        "ç«‹ã£ã¦",
        "ãƒ€ãƒ³ã‚¹ã—ã¦",
        "åœæ­¢"
    ]
    
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯• ({len(test_cases)}ä¸ªæ¡ˆä¾‹):")
    
    total_start = time.time()
    results = []
    
    for i, command in enumerate(test_cases, 1):
        print(f"\n[{i}/{len(test_cases)}] æµ‹è¯•: '{command}'")
        
        start_time = time.time()
        response = llm.generate_response(f"æŒ‡ä»¤: {command}")
        end_time = time.time()
        
        duration = end_time - start_time
        success = not response.startswith("âŒ")
        
        results.append({
            "command": command,
            "duration": duration,
            "success": success,
            "response_length": len(response)
        })
        
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"  {status} - {duration:.2f}ç§’ - {len(response)}å­—ç¬¦")
    
    # 4. æ€§èƒ½ç»Ÿè®¡
    total_time = time.time() - total_start
    success_count = sum(1 for r in results if r["success"])
    avg_time = sum(r["duration"] for r in results) / len(results)
    
    print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"  æˆåŠŸç‡: {success_count}/{len(test_cases)} ({success_count/len(test_cases)*100:.1f}%)")
    print(f"  å¹³å‡å“åº”: {avg_time:.2f}ç§’")
    print(f"  æœ€å¿«å“åº”: {min(r['duration'] for r in results):.2f}ç§’")
    print(f"  æœ€æ…¢å“åº”: {max(r['duration'] for r in results):.2f}ç§’")
    
    # 5. è¯„ä¼°ä¼˜åŒ–æ•ˆæœ
    print(f"\nğŸ¯ ä¼˜åŒ–æ•ˆæœè¯„ä¼°:")
    
    # ç›®æ ‡æ€§èƒ½æŒ‡æ ‡
    target_avg_time = 3.0  # ç›®æ ‡å¹³å‡å“åº”æ—¶é—´
    target_success_rate = 90  # ç›®æ ‡æˆåŠŸç‡
    
    if avg_time <= target_avg_time:
        print(f"  âœ… å“åº”é€Ÿåº¦: {avg_time:.2f}s â‰¤ {target_avg_time}s (è¾¾æ ‡)")
    else:
        print(f"  âš ï¸ å“åº”é€Ÿåº¦: {avg_time:.2f}s > {target_avg_time}s (éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–)")
    
    success_rate = success_count/len(test_cases)*100
    if success_rate >= target_success_rate:
        print(f"  âœ… æˆåŠŸç‡: {success_rate:.1f}% â‰¥ {target_success_rate}% (è¾¾æ ‡)")
    else:
        print(f"  âš ï¸ æˆåŠŸç‡: {success_rate:.1f}% < {target_success_rate}% (éœ€è¦æ”¹è¿›)")
    
    # 6. ä¼˜åŒ–å»ºè®®
    if avg_time > target_avg_time:
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print(f"  - è¿›ä¸€æ­¥å‡å°‘num_predictå‚æ•°")
        print(f"  - è°ƒæ•´temperatureåˆ°æ›´ä½å€¼")
        print(f"  - æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿå’Œç¡¬ä»¶æ€§èƒ½")
    
    return results

async def test_enhanced_interface():
    """æµ‹è¯•å¢å¼ºç•Œé¢çš„æ€§èƒ½"""
    print(f"\nğŸ¤– æµ‹è¯•å¢å¼ºç•Œé¢...")
    
    try:
        from src.claudia.interactive_japanese_commander_enhanced import EnhancedJapaneseCommandInterface
        
        interface = EnhancedJapaneseCommandInterface()
        await interface.initialize()
        
        # æµ‹è¯•å•ä¸ªå‘½ä»¤å¤„ç†
        test_command = "åº§ã‚‹"
        print(f"  æµ‹è¯•å‘½ä»¤: {test_command}")
        
        start_time = time.time()
        result = await interface.process_japanese_command(test_command)
        end_time = time.time()
        
        total_time = end_time - start_time
        success = result.get("success", False)
        
        print(f"  ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # åˆ†æè€—æ—¶åˆ†å¸ƒ
        if "llm_analysis" in result:
            llm_time = result["llm_analysis"].get("analysis_time", 0)
            print(f"  LLMåˆ†æ: {llm_time:.2f}ç§’")
        
        if "execution_result" in result:
            exec_time = result["execution_result"].get("total_time", 0)
            print(f"  åŠ¨ä½œæ‰§è¡Œ: {exec_time:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å¢å¼ºç•Œé¢æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. åŸºç¡€LLMæ€§èƒ½æµ‹è¯•
        llm_results = test_performance_optimization()
        
        # 2. å¢å¼ºç•Œé¢æµ‹è¯•
        asyncio.run(test_enhanced_interface())
        
        print(f"\nğŸ‰ æ€§èƒ½éªŒè¯å®Œæˆï¼")
        
        # æ¨èä¸‹ä¸€æ­¥
        avg_time = sum(r["duration"] for r in llm_results) / len(llm_results)
        if avg_time <= 3.0:
            print(f"âœ… æ€§èƒ½ä¼˜åŒ–æˆåŠŸï¼Œå»ºè®®æŠ•å…¥ç”Ÿäº§ä½¿ç”¨")
        else:
            print(f"âš ï¸ è¿˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œå»ºè®®ç»§ç»­è°ƒæ•´å‚æ•°")
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main() 