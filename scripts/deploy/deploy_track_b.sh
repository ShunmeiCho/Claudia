#!/bin/bash
# Track Béƒ¨ç½²è„šæœ¬ï¼šæ‹‰å–/åˆ›å»ºæ–°æ¨¡å‹å¹¶å¿«é€Ÿæµ‹è¯•

set -e

cd $HOME/claudia

echo "=================================="
echo "ğŸ”¬ Track B: æ–°æ¨¡å‹éƒ¨ç½²"
echo "=================================="
echo ""

# 1. ç¡®ä¿åŸºç¡€æ¨¡å‹å­˜åœ¨
echo "ğŸ“¦ æ£€æŸ¥åŸºç¡€æ¨¡å‹..."
if ! ollama list | grep -q "qwen2.5:7b"; then
    echo "â¬‡ï¸  æ‹‰å–qwen2.5:7b (çº¦4.7GB, INT4é‡åŒ–)..."
    ollama pull qwen2.5:7b
else
    echo "   âœ… qwen2.5:7bå·²å­˜åœ¨"
fi

# 2. åˆ›å»ºæ–°Modelfileæ¨¡å‹
echo ""
echo "ğŸ”§ åˆ›å»ºclaudia-intelligent-7b:v1..."
if ollama list | grep -q "claudia-intelligent-7b:v1"; then
    echo "   âš ï¸  æ¨¡å‹å·²å­˜åœ¨ï¼Œåˆ é™¤æ—§ç‰ˆæœ¬..."
    ollama rm claudia-intelligent-7b:v1 2>/dev/null || true
fi

ollama create claudia-intelligent-7b:v1 -f ClaudiaIntelligent_Qwen7B

echo "   âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ"

# 3. å¿«é€Ÿæµ‹è¯•ï¼ˆä¿®å¤ï¼šä½¿ç”¨Pythonåº“æ›¿ä»£CLI --format jsonï¼‰
echo ""
echo "ğŸ§ª å¿«é€Ÿæµ‹è¯•æ–°æ¨¡å‹..."
echo ""

python3 - <<'PYEOF'
import ollama
import json

test_commands = [
    "åº§ã£ã¦",
    "ç«‹ã£ã¦",
    "å¯æ„›ã„",
    "stop"
]

print("ä½¿ç”¨Python ollamaåº“æµ‹è¯• (format='json')...\n")
for cmd in test_commands:
    print(f"æµ‹è¯•: {cmd}")
    try:
        response = ollama.chat(
            model="claudia-intelligent-7b:v1",
            messages=[{'role': 'user', 'content': cmd}],
            format='json',
            options={'temperature': 0.1, 'num_predict': 30}
        )
        content = response['message']['content']
        data = json.loads(content)
        api_code = data.get('api_code') or data.get('a')
        print(f"  â†’ api_code: {api_code}")
        print(f"  â†’ raw: {content[:80]}...")
    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
    print("")
PYEOF

echo "=================================="
echo "âœ… Track Béƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ä¸‹ä¸€æ­¥ï¼š"
echo "1. è¿è¡Œå®Œæ•´è¯„æµ‹: python3 test/test_model_comparison.py"
echo "2. å¯¹æ¯”ç»“æœæŸ¥çœ‹: test/model_comparison_results.json"
echo "=================================="
